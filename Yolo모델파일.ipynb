{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DEFINER24/2025DCC/blob/main/Yolo%EB%AA%A8%EB%8D%B8%ED%8C%8C%EC%9D%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP_5EISC4vmF"
      },
      "source": [
        "# YOLO 모델 파일\n",
        "## 0. 구글 드라이브 마운트 및 압축 해제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4-hPB4E4tDL",
        "outputId": "3eb4c77a-51e3-46f5-d175-d8ca35902c92"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ==========================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 0. 구글 드라이브 마운트 및 압축 해제\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ==========================================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      5\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# 0. 구글 드라이브 마운트 및 압축 해제\n",
        "# ==========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile, os\n",
        "from pathlib import Path\n",
        "\n",
        "# ZIP 파일 경로 지정\n",
        "zip_path = '/content/drive/MyDrive/model_data/Model_data.zip'\n",
        "extract_path = '/content/drive/MyDrive/data_model'\n",
        "\n",
        "# 압축 해제\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"압축 해제 완료: {extract_path}\")\n",
        "else:\n",
        "    print(\"⚠️ Model_data.zip 파일을 찾을 수 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTb6-0Md-u_b",
        "outputId": "8d0f2287-f36b-4412-a906-0ae1604a1f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: images 68376개, labels 68376개\n",
            "val: images 8545개, labels 8545개\n",
            "test: images 8545개, labels 8545개\n"
          ]
        }
      ],
      "source": [
        "# 압축 해제 후 폴더 구조 점검\n",
        "import os\n",
        "for folder in ['train', 'val', 'test']:\n",
        "    full_path = os.path.join('./Model_data', folder)\n",
        "    if os.path.exists(full_path):\n",
        "        n_img = len(os.listdir(os.path.join(full_path, 'images')))\n",
        "        n_lbl = len(os.listdir(os.path.join(full_path, 'labels_json')))\n",
        "        print(f\"{folder}: images {n_img}개, labels {n_lbl}개\")\n",
        "    else:\n",
        "        print(f\"{folder} 폴더가 존재하지 않습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjVRdYHwHVLj"
      },
      "source": [
        "## 본 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aU_UHkMuQuQs"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# 0. 환경 설정 및 라이브러리 설치\n",
        "# ==========================================================\n",
        "#!pip -q install ultralytics==8.3.50\n",
        "import os, json, glob, random\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch: 2.5.1+cu121\n",
            "GPU available: True\n"
          ]
        }
      ],
      "source": [
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"GPU available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JqBVO4R4Qx8g"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# 1. 구글 드라이브 마운트 및 데이터 경로 지정\n",
        "# ==========================================================\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# 실제 폴더 구조 반영\n",
        "DATA_ROOT = Path('./Model_data').resolve()\n",
        "assert (DATA_ROOT / 'train').exists(), \"train 폴더 없음\"\n",
        "assert (DATA_ROOT / 'val').exists(), \"val 폴더 없음\"\n",
        "assert (DATA_ROOT / 'test').exists(), \"test 폴더 없음\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u4hi7tofQ0_S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLASS_TO_ID: {'pipe': 0, 'box': 1, 'manhole': 2, 'patch': 3, 'cavity': 4}\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# 2. 클래스 정의\n",
        "# ==========================================================\n",
        "CLASS_NAMES = ['pipe', 'box', 'manhole', 'patch', 'cavity']\n",
        "CLASS_TO_ID = {c: i for i, c in enumerate(CLASS_NAMES)}\n",
        "print(\"CLASS_TO_ID:\", CLASS_TO_ID)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_W, IMG_H = 300, 256      # 모든 GPR 이미지 해상도           # XZ 평면만 사용 (전부 사용하려면 None)\n",
        "\n",
        "def parse_one_json(jpath: Path, img_dir: Path):\n",
        "    with open(jpath, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    plane = (data.get('plane') or '').strip().upper()\n",
        "\n",
        "    img_name = data.get('fileName')\n",
        "    img_path = img_dir / img_name\n",
        "    # targetType으로 클래스 결정\n",
        "    target = (data.get('targetType') or '').strip().lower()\n",
        "    if target not in CLASS_TO_ID:\n",
        "        return img_path, [], plane\n",
        "\n",
        "    cid = CLASS_TO_ID[target]\n",
        "    ann = data.get('annotation', {})\n",
        "    anns = ann if isinstance(ann, list) else [ann]\n",
        "    yolo_lines = []\n",
        "\n",
        "    for a in anns:\n",
        "        if not all(k in a for k in ('bbox_x', 'bbox_y', 'bbox_w', 'bbox_h')):\n",
        "            continue\n",
        "        bx, by = float(a['bbox_x']), float(a['bbox_y'])\n",
        "        bw, bh = float(a['bbox_w']), float(a['bbox_h'])\n",
        "        if a.get('bbox_xM') and a.get('bbox_yM'):\n",
        "            try:\n",
        "                bxM, byM = float(a['bbox_xM']), float(a['bbox_yM'])\n",
        "                bw = max(1.0, bxM - bx)\n",
        "                bh = max(1.0, byM - by)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # YOLO 좌표 정규화\n",
        "        cx = (bx + bw/2.0) / IMG_W\n",
        "        cy = (by + bh/2.0) / IMG_H\n",
        "        nw = bw / IMG_W\n",
        "        nh = bh / IMG_H\n",
        "        cx = min(max(cx, 0.0), 1.0)\n",
        "        cy = min(max(cy, 0.0), 1.0)\n",
        "        nw = min(max(nw, 0.0), 1.0)\n",
        "        nh = min(max(nh, 0.0), 1.0)\n",
        "\n",
        "        yolo_lines.append(f\"{cid} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\")\n",
        "\n",
        "    return img_path, yolo_lines, plane\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iFepaWzGQ6jD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] 변환 성공: 68376, 제외: 0, 이미지없음: 0, 라벨없음: 0\n",
            "[train] 클래스 분포: {'pipe': 27467, 'box': 8737, 'manhole': 10395, 'patch': 9607, 'cavity': 12170}\n",
            "[val] 변환 성공: 8545, 제외: 0, 이미지없음: 0, 라벨없음: 0\n",
            "[val] 클래스 분포: {'pipe': 3433, 'box': 1092, 'manhole': 1299, 'patch': 1200, 'cavity': 1521}\n",
            "[test] 변환 성공: 8545, 제외: 0, 이미지없음: 0, 라벨없음: 0\n",
            "[test] 클래스 분포: {'pipe': 3433, 'box': 1092, 'manhole': 1299, 'patch': 1200, 'cavity': 1521}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8545"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# 4. YZ 평면 데이터만 변환\n",
        "# ==========================================================\n",
        "def convert_split(split_name: str):\n",
        "    split_dir = DATA_ROOT / split_name\n",
        "    img_dir   = split_dir / 'images'\n",
        "    json_dir  = split_dir / 'labels_json'        # 원본 JSON\n",
        "    yolo_lbl  = split_dir / 'labels'   # 변환 결과 저장\n",
        "    yolo_lbl.mkdir(exist_ok=True)\n",
        "\n",
        "    json_files = sorted(glob.glob(str(json_dir / '*.json')))\n",
        "    ok, skip, noimg, noline = 0, 0, 0, 0\n",
        "    per_class_counts = {k: 0 for k in CLASS_NAMES}\n",
        "\n",
        "    for jp in json_files:\n",
        "        jp = Path(jp)\n",
        "        img_path, yolo_lines, plane = parse_one_json(jp, img_dir)\n",
        "\n",
        "        if img_path is None and yolo_lines is None:\n",
        "            skip += 1\n",
        "            continue\n",
        "        if img_path is None:\n",
        "            noimg += 1\n",
        "            continue\n",
        "        if not yolo_lines:\n",
        "            noline += 1\n",
        "            continue\n",
        "\n",
        "        out_lbl = yolo_lbl / f\"{img_path.stem}.txt\"\n",
        "        with open(out_lbl, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(yolo_lines))\n",
        "\n",
        "        cid = int(yolo_lines[0].split()[0])\n",
        "        per_class_counts[CLASS_NAMES[cid]] += 1\n",
        "        ok += 1\n",
        "\n",
        "    print(f\"[{split_name}] 변환 성공: {ok}, 제외: {skip}, 이미지없음: {noimg}, 라벨없음: {noline}\")\n",
        "    print(f\"[{split_name}] 클래스 분포:\", per_class_counts)\n",
        "    return ok\n",
        "\n",
        "convert_split('train')\n",
        "convert_split('val')\n",
        "convert_split('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HrlMP_8GQ78p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ data.yaml 생성 완료: C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\data.yaml\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# 5. data.yaml 생성\n",
        "# ==========================================================\n",
        "YAML_PATH = DATA_ROOT / 'data.yaml'\n",
        "yaml_text = f\"\"\"\n",
        "path: {DATA_ROOT.as_posix()}\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "names:\n",
        "  0: pipe\n",
        "  1: box\n",
        "  2: manhole\n",
        "  3: patch\n",
        "  4: cavity\n",
        "\"\"\"\n",
        "with open(YAML_PATH, 'w', encoding='utf-8') as f:\n",
        "    f.write(yaml_text)\n",
        "print(f\"✅ data.yaml 생성 완료: {YAML_PATH}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9aAnfRMIQ-RL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.214 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.50  Python-3.12.10 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11m.pt, data=C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\data.yaml, epochs=5, time=None, patience=100, batch=-1, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=8, project=C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs, name=yolo_model, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs\\yolo_model\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 23        [16, 19, 22]  1   1414879  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
            "YOLO11m summary: 409 layers, 20,056,863 parameters, 20,056,847 gradients, 68.2 GFLOPs\n",
            "\n",
            "Transferred 643/649 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\train\\labels.cache... 68376 images, 0 backgrounds, 0 corrupt: 100%|██████████| 68376/68376 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=320 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU) 8.00G total, 0.19G reserved, 0.18G allocated, 7.62G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "    20056863       17.05         0.415         99.15           252        (1, 3, 320, 320)                    list\n",
            "    20056863        34.1         0.514         97.02         108.4        (2, 3, 320, 320)                    list\n",
            "    20056863       68.21         0.763          51.5         63.33        (4, 3, 320, 320)                    list\n",
            "    20056863       136.4         1.294         54.16         74.42        (8, 3, 320, 320)                    list\n",
            "    20056863       272.8         2.290         65.04          79.5       (16, 3, 320, 320)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 34 for CUDA:0 4.94G/8.00G (62%) \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\train\\labels.cache... 68376 images, 0 backgrounds, 0 corrupt: 100%|██████████| 68376/68376 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\val\\labels.cache... 8545 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8545/8545 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs\\yolo_model\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.00053125), 112 bias(decay=0.0)\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs\\yolo_model\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/5      4.73G     0.6491      1.626      1.146          5        320: 100%|██████████| 2012/2012 [10:31<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 126/126 [00:49<00:00,  2.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       8545       8545      0.322      0.739      0.365      0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        2/5      4.86G     0.5296      1.397      1.081          8        320: 100%|██████████| 2012/2012 [10:17<00:00,  3.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 126/126 [00:46<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       8545       8545      0.449      0.804      0.511      0.468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        3/5      4.92G       0.47      1.314      1.052          5        320: 100%|██████████| 2012/2012 [09:33<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 126/126 [00:46<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       8545       8545      0.452      0.813      0.535      0.489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        4/5      4.92G      0.431      1.253       1.03          6        320: 100%|██████████| 2012/2012 [09:36<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 126/126 [00:52<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       8545       8545      0.471      0.847      0.574      0.537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        5/5       4.9G     0.3919      1.186      1.009          3        320: 100%|██████████| 2012/2012 [09:52<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 126/126 [00:51<00:00,  2.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       8545       8545      0.513      0.859       0.59      0.555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "5 epochs completed in 0.902 hours.\n",
            "Optimizer stripped from C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs\\yolo_model\\weights\\last.pt, 40.5MB\n",
            "Optimizer stripped from C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs\\yolo_model\\weights\\best.pt, 40.5MB\n",
            "\n",
            "Validating C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs\\yolo_model\\weights\\best.pt...\n",
            "Ultralytics 8.3.50  Python-3.12.10 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
            "YOLO11m summary (fused): 303 layers, 20,033,887 parameters, 0 gradients, 67.7 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 126/126 [00:59<00:00,  2.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       8545       8545      0.513      0.859       0.59      0.555\n",
            "                  pipe       3433       3433       0.48      0.923      0.519      0.498\n",
            "                   box       1092       1092      0.476      0.826      0.487      0.449\n",
            "               manhole       1299       1299      0.658      0.965       0.91      0.862\n",
            "                 patch       1200       1200      0.469      0.764      0.506       0.45\n",
            "                cavity       1521       1521      0.481      0.819      0.529      0.517\n",
            "Speed: 0.1ms preprocess, 1.9ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs\\yolo_model\u001b[0m\n",
            "최적 가중치 경로: C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\runs\\yolo_model\\weights\\best.pt\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# 6. YOLO 모델 학습 (yz 평면 데이터만)\n",
        "# ==========================================================\n",
        "MODEL_NAME = 'yolo11m.pt'\n",
        "IMG_SIZE   = 320\n",
        "EPOCHS     = 5\n",
        "#EPOCHS     = 100 --- IGNORE ---\n",
        "BATCH      = -1\n",
        "\n",
        "model = YOLO(MODEL_NAME)\n",
        "results = model.train(\n",
        "    data=str(YAML_PATH),\n",
        "    imgsz=IMG_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    batch=BATCH,\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    project=str(DATA_ROOT / 'runs'),\n",
        "    name='yolo_model',\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "best_ckpt = Path(results.save_dir) / 'weights' / 'best.pt'\n",
        "print(\"최적 가중치 경로:\", best_ckpt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZfCJVeTbRAvu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.50  Python-3.12.10 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
            "YOLO11m summary (fused): 303 layers, 20,033,887 parameters, 0 gradients, 67.7 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\Model_data\\test\\labels.cache... 8545 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8545/8545 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 535/535 [01:06<00:00,  8.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       8545       8545      0.519      0.856      0.599       0.56\n",
            "                  pipe       3433       3433      0.483      0.917      0.524      0.502\n",
            "                   box       1092       1092      0.482      0.829      0.495      0.456\n",
            "               manhole       1299       1299       0.68       0.96      0.913       0.86\n",
            "                 patch       1200       1200      0.471      0.737      0.515      0.444\n",
            "                cavity       1521       1521      0.481      0.837       0.55       0.54\n",
            "Speed: 0.1ms preprocess, 3.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mc:\\Users\\k0107\\Documents\\GitHub\\2025DCC\\runs\\detect\\val5\u001b[0m\n",
            "mAP@IoU=0.5: 0.5994\n"
          ]
        }
      ],
      "source": [
        "best_model = YOLO(best_ckpt)\n",
        "val_res = best_model.val(\n",
        "    data=str(YAML_PATH),\n",
        "    split='test',\n",
        "    imgsz=IMG_SIZE,\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    conf=0.001,\n",
        "    iou=0.5,\n",
        "    max_det=3000\n",
        ")\n",
        "\n",
        "stats = val_res.results_dict\n",
        "mAP50 = float(stats['metrics/mAP50(B)'])\n",
        "print(f\"mAP@IoU=0.5: {mAP50:.4f}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
